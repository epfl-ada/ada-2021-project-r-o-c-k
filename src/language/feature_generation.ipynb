{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bz2\n",
    "import json\n",
    "from feature_generation_par import add_features_to_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Features for each year and save them as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:13<00:00,  4.60it/s]\n",
      "100%|██████████| 64/64 [00:01<00:00, 50.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:14<00:00,  4.27it/s]\n",
      "100%|██████████| 64/64 [00:01<00:00, 47.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:15<00:00,  4.09it/s]\n",
      "100%|██████████| 64/64 [00:01<00:00, 38.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:17<00:00,  3.70it/s]\n",
      "100%|██████████| 64/64 [00:01<00:00, 46.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:17<00:00,  3.67it/s]\n",
      "100%|██████████| 64/64 [00:01<00:00, 42.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:18<00:00,  3.54it/s]\n",
      "100%|██████████| 64/64 [00:01<00:00, 38.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:21<00:00,  2.95it/s]\n",
      "100%|██████████| 64/64 [00:01<00:00, 36.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:19<00:00,  3.33it/s]\n",
      "100%|██████████| 64/64 [00:01<00:00, 33.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:18<00:00,  3.41it/s]\n",
      "100%|██████████| 64/64 [00:01<00:00, 35.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/64 [00:03<03:10,  3.03s/it]"
     ]
    }
   ],
   "source": [
    "years = ['2020'] #['2015', '2016', '2017', '2018', '2019', '2020']\n",
    "data_folder_path = './../../data/' #to data subdirectory in root folder of repo\n",
    "file_prefix_r = 'quotes-'\n",
    "file_suffix_r = '_preprocessed.json.bz2'\n",
    "generate_path = './../../generated/' #to generated subdirectory in root folder of repo\n",
    "file_prefix_w = 'quotes-'\n",
    "file_suffix_w = '_with_language_feats.csv'\n",
    "header = False\n",
    "for year in years:\n",
    "    # read the file from year\n",
    "    file_name_r = file_prefix_r + year + file_suffix_r\n",
    "    df_quotes_chunks = pd.read_json(data_folder_path + file_name_r, lines=True, compression='bz2', chunksize = 10000)\n",
    "    for i, df_chunk in enumerate(df_quotes_chunks):\n",
    "        if i == 1: \n",
    "            header = False\n",
    "            \n",
    "        # add language features and append to csv\n",
    "        print(\"Chunk: \" + str(i))\n",
    "        file_name_w = file_prefix_w + year + file_suffix_w\n",
    "        df_all_features_chunk = add_features_to_df(df_chunk)\n",
    "        df_all_features_chunk.to_csv(generate_path + file_name_w, header = header, mode = 'a')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ddbd0b842a978e03471eb3a4ae18fdd24eb8ad76bdab23b363108c4c8f6a59c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('ada': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
