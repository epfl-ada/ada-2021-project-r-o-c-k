{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9628f57",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "797d577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bz2\n",
    "import json\n",
    "from os.path import join\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import datasets, cluster\n",
    "import numpy as np\n",
    "from grammar_mappings import dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a70c25f",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e160bed2",
   "metadata": {},
   "source": [
    "### Speaker features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "104f8303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2654370, 7)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = '../../data/speaker_features'\n",
    "speaker_filename = 'df_speaker_cooked.csv.gzip'\n",
    "\n",
    "df_speaker = pd.read_csv(join(dir_path, speaker_filename), compression='gzip')\n",
    "df_speaker.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_speaker.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7e21ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>nationality</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>academic_degree</th>\n",
       "      <th>religion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q42</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Male</td>\n",
       "      <td>Arts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q207</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Male</td>\n",
       "      <td>Politics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q633</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Male</td>\n",
       "      <td>Arts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q640</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>Arts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q853</td>\n",
       "      <td>1932.0</td>\n",
       "      <td>Soviet Union</td>\n",
       "      <td>Male</td>\n",
       "      <td>Arts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Christian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  date_of_birth               nationality gender occupation  \\\n",
       "0   Q42         1952.0            United Kingdom   Male       Arts   \n",
       "1  Q207         1946.0  United States of America   Male   Politics   \n",
       "2  Q633         1945.0                    Canada   Male       Arts   \n",
       "3  Q640         1969.0                   Germany   Male       Arts   \n",
       "4  Q853         1932.0              Soviet Union   Male       Arts   \n",
       "\n",
       "  academic_degree   religion  \n",
       "0             NaN        NaN  \n",
       "1             NaN  Christian  \n",
       "2             NaN        NaN  \n",
       "3             NaN        NaN  \n",
       "4             NaN  Christian  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_speaker.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "098d39e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2654370"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_speaker.id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c803d719",
   "metadata": {},
   "source": [
    "### Language features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "29783b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(df_quotes, df_speaker):\n",
    "    df_quotes = df_quotes.set_index('qid')\n",
    "    \n",
    "    # drop duplicate rows (mostly data headers)\n",
    "    df_quotes.drop_duplicates(inplace=True)\n",
    "    df_quotes = df_quotes[df_quotes.quoteID.str.contains('quoteID') == False]\n",
    "    \n",
    "    # change value type\n",
    "    for field in df_quotes.columns:\n",
    "        df_quotes[field] = df_quotes[field].astype(dtypes[field], errors = 'raise')\n",
    "    \n",
    "    # merge df\n",
    "    df = df_quotes.merge(df_speaker.set_index('id'), left_index=True, right_index=True)\n",
    " #   df = df_quotes.merge(df_speaker, left_on='qid', right_on='id')\n",
    " \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "650086c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_data_2020_new.csv.gzip\n",
      "0 (446142, 31)\n",
      "merged_data_2020_new.csv.gzip\n",
      "1 (446168, 31)\n",
      "merged_data_2020_new.csv.gzip\n",
      "2 (43253, 31)\n"
     ]
    }
   ],
   "source": [
    "dir_path = 'D:/ADA_quotebank/language_features'\n",
    "filename = 'quotes-2020_with_language_feats.csv' # change years\n",
    "outname = \"merged_data_2020_new.csv.gzip\" # change years\n",
    "\n",
    "chunksize = 500000\n",
    "df = pd.DataFrame()\n",
    "flag = True\n",
    "save = True\n",
    "i = 0\n",
    "\n",
    "for chunk in pd.read_csv(join(dir_path, filename), chunksize=chunksize, usecols=dtypes.keys(), dtype='O'):\n",
    "    df = merge(chunk, df_speaker)\n",
    "    if save:\n",
    "        if flag:\n",
    "            df.to_csv(join(dir_path, outname), index=False, compression=\"gzip\", mode='a')\n",
    "            flag = False\n",
    "        df.to_csv(join(dir_path, outname), index=False, compression=\"gzip\", mode='a', header=False)\n",
    "    print(i, df.shape)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aca08ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check files were saved\n",
    "dir_path = 'D:/ADA_quotebank/language_features'\n",
    "filename = \"merged_data_2015.csv.gzip\"\n",
    "\n",
    "chunksize = 1000000\n",
    "for chunk in pd.read_csv(join(dir_path, filename), chunksize=chunksize, compression='gzip'):\n",
    "    df = chunk\n",
    "    break\n",
    "    \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "040bd68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = pd.read_csv(join(dir_path, outname), compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "245d5b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1381705, 31)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7f5dd035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(935563, 31)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.drop_duplicates(inplace=True)\n",
    "test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c5df197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.to_csv(join(dir_path, outname), index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c62cf3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9092833, 33)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "380555ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['quoteID', 'qid', 'sentence_count', '._per_sentence', ',_per_sentence',\n",
       "       '!_per_sentence', '?_per_sentence', ':_per_sentence', ';_per_sentence',\n",
       "       'sign_per_token', 'punctuation_per_sentence', 'approx_word_count',\n",
       "       'token_count', 'adj_per_word', 'ordinal_ratio', 'comparative_ratio',\n",
       "       'superlative_ratio', 'verb_per_word', 'base_ratio', 'pres_ratio',\n",
       "       'past_ratio', 'pronoun_per_word', 'self_ratio', 'union_ratio',\n",
       "       'other_ratio', 'sentiment', 'Unnamed: 0', 'date_of_birth',\n",
       "       'nationality', 'gender', 'occupation', 'academic_degree', 'religion'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "08069359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8648223, 33)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.drop_duplicates(inplace=True)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7652e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"merged_data_2015_new.csv.gzip\"\n",
    "test.to_csv(join(dir_path, filename), index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dfaa3335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(553858, 32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d31e2722",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_language = ['sentence_count', '._per_sentence', ',_per_sentence', '!_per_sentence', '?_per_sentence', ':_per_sentence',\n",
    " ';_per_sentence', 'sign_per_token', 'punctuation_per_sentence', 'approx_word_count', 'token_count', 'adj_per_word',\n",
    " 'ordinal_ratio', 'comparative_ratio', 'superlative_ratio', 'verb_per_word', 'base_ratio', 'pres_ratio', 'past_ratio',\n",
    " 'pronoun_per_word', 'self_ratio', 'union_ratio', 'other_ratio', 'sentiment']\n",
    "\n",
    "ft_speaker = ['date_of_birth', 'nationality', 'gender', 'occupation', 'academic_degree', 'religion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e6cff3",
   "metadata": {},
   "source": [
    "### Tree-based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "973de128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_feature_select(X, y):\n",
    "    '''\n",
    "    Does feature selection using decision trees\n",
    "    \n",
    "    :param X: features (n_rows, n_features)\n",
    "    :param y: target (n_rows,)\n",
    "    :return clf: extra trees classifiers\n",
    "    :return model: model with reduced features\n",
    "    '''\n",
    "    clf = ExtraTreesClassifier(n_estimators=50)\n",
    "    clf = clf.fit(X, y)\n",
    "    model = SelectFromModel(clf, prefit=True)\n",
    "    \n",
    "    return clf, model\n",
    "\n",
    "\n",
    "def select_predictors(df, ft_language, target):\n",
    "    '''\n",
    "    Extracts portion of the df and extracts the most relevant features based on a target speaker attribute\n",
    "    \n",
    "    :param df: merged dataframe with language and speaker features\n",
    "    :param ft_language: list of language features\n",
    "    :param target: target speaker attribute to predict\n",
    "    :return clf: extra trees classifier\n",
    "    :return model: selected model\n",
    "    :return shape: shape of the data used (some target speaker features have nan which needs to be removed)\n",
    "    :return X: features used to get model\n",
    "    :return y: targets used to get model\n",
    "    '''\n",
    "    temp = df[ft_language].copy()\n",
    "    temp[target] = df[target]\n",
    "    temp.dropna(inplace=True)\n",
    "    \n",
    "    X = temp[ft_language].to_numpy()\n",
    "    y = temp[target].to_numpy()\n",
    "    clf, model = tree_feature_select(X, y)\n",
    "    clf.feature_importances_\n",
    "    \n",
    "    return clf, model, temp.shape, X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee43d41",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c1cb4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data size: (1000000, 25)\n",
      "[',_per_sentence' 'sign_per_token' 'approx_word_count' 'token_count'\n",
      " 'adj_per_word' 'verb_per_word' 'base_ratio' 'pres_ratio' 'past_ratio'\n",
      " 'pronoun_per_word' 'sentiment']\n",
      "[0.02130124 0.00715211 0.0458133  0.0056248  0.00507215 0.00443799\n",
      " 0.00429285 0.07143094 0.00519523 0.06671137 0.07008564 0.07603384\n",
      " 0.01274571 0.01064285 0.00906929 0.08930027 0.04780305 0.0500179\n",
      " 0.04409552 0.06293489 0.01288144 0.00988345 0.0116365  0.25583765]\n"
     ]
    }
   ],
   "source": [
    "target = 'gender'\n",
    "clf, model, size, X, y = select_predictors(df, ft_language, target)\n",
    "ft_selected = model.get_feature_names_out(ft_language)\n",
    "ft_importance = clf.feature_importances_\n",
    "print('Input data size: ' + str(size))\n",
    "print(ft_selected)\n",
    "print(ft_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f0d38c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>,_per_sentence</th>\n",
       "      <th>sign_per_token</th>\n",
       "      <th>approx_word_count</th>\n",
       "      <th>token_count</th>\n",
       "      <th>adj_per_word</th>\n",
       "      <th>verb_per_word</th>\n",
       "      <th>base_ratio</th>\n",
       "      <th>pres_ratio</th>\n",
       "      <th>past_ratio</th>\n",
       "      <th>pronoun_per_word</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>32.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ,_per_sentence  sign_per_token  approx_word_count  token_count  \\\n",
       "0             0.0        0.250000                9.0         12.0   \n",
       "1             0.0        0.085714               32.0         35.0   \n",
       "2             1.0        0.200000                8.0         10.0   \n",
       "3             1.0        0.041667               23.0         24.0   \n",
       "4             0.0        0.066667               14.0         15.0   \n",
       "\n",
       "   adj_per_word  verb_per_word  base_ratio  pres_ratio  past_ratio  \\\n",
       "0      0.333333       0.333333        -1.0         1.0        -1.0   \n",
       "1      0.062500       0.187500         0.0         0.0        -1.0   \n",
       "2      0.375000       0.000000         0.0         0.0         0.0   \n",
       "3      0.043478       0.217391         0.2        -0.6        -0.6   \n",
       "4      0.000000       0.142857        -1.0         0.0         0.0   \n",
       "\n",
       "   pronoun_per_word  sentiment  \n",
       "0           0.00000     -0.478  \n",
       "1           0.09375      0.301  \n",
       "2           0.00000     -0.636  \n",
       "3           0.00000      0.291  \n",
       "4           0.00000      0.000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = model.transform(X)\n",
    "df_new = pd.DataFrame(X_new, columns=ft_selected)\n",
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1473016",
   "metadata": {},
   "source": [
    "#### Academic degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16dd68b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data size: (66817, 25)\n",
      "[',_per_sentence' 'sign_per_token' 'approx_word_count' 'token_count'\n",
      " 'adj_per_word' 'verb_per_word' 'base_ratio' 'pres_ratio' 'past_ratio'\n",
      " 'pronoun_per_word' 'sentiment']\n",
      "[0.01902612 0.00742463 0.0499002  0.00439234 0.00526699 0.00643946\n",
      " 0.00426018 0.07748047 0.00456877 0.07604585 0.07813609 0.0758923\n",
      " 0.01116957 0.00924575 0.00790786 0.09265254 0.05752249 0.06138377\n",
      " 0.05186353 0.05350653 0.0152148  0.01376018 0.0160531  0.20088647]\n"
     ]
    }
   ],
   "source": [
    "target = 'academic_degree'\n",
    "clf, model, size, X, y = select_predictors(df, ft_language, target)\n",
    "ft_selected = model.get_feature_names_out(ft_language)\n",
    "ft_importance = clf.feature_importances_\n",
    "print('Input data size: ' + str(size))\n",
    "print(ft_selected)\n",
    "print(ft_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40909165",
   "metadata": {},
   "source": [
    "#### Religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa8542f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data size: (228978, 25)\n",
      "[',_per_sentence' 'sign_per_token' 'approx_word_count' 'token_count'\n",
      " 'adj_per_word' 'verb_per_word' 'base_ratio' 'pres_ratio' 'past_ratio'\n",
      " 'pronoun_per_word' 'sentiment']\n",
      "[0.02118925 0.00911508 0.04787876 0.00448275 0.00693642 0.00479673\n",
      " 0.00415829 0.0723747  0.00544839 0.07116436 0.07407169 0.07415109\n",
      " 0.01326976 0.01095889 0.00975449 0.087494   0.05099884 0.0529414\n",
      " 0.04496076 0.05835626 0.01876152 0.01717369 0.02040654 0.21915636]\n"
     ]
    }
   ],
   "source": [
    "target = 'religion'\n",
    "clf, model, size, X, y = select_predictors(df, ft_language, target)\n",
    "ft_selected = model.get_feature_names_out(ft_language)\n",
    "ft_importance = clf.feature_importances_\n",
    "print('Input data size: ' + str(size))\n",
    "print(ft_selected)\n",
    "print(ft_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a010440b",
   "metadata": {},
   "source": [
    "#### Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e21ac3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data size: (986161, 25)\n",
      "[',_per_sentence' 'sign_per_token' 'approx_word_count' 'token_count'\n",
      " 'adj_per_word' 'verb_per_word' 'base_ratio' 'pres_ratio' 'past_ratio'\n",
      " 'pronoun_per_word' 'sentiment']\n",
      "[0.02102178 0.00886067 0.04579123 0.00448464 0.00542813 0.00409131\n",
      " 0.00422546 0.07032331 0.0058153  0.06528612 0.0688696  0.07679083\n",
      " 0.01463542 0.01229463 0.01040372 0.08600327 0.04751286 0.05153817\n",
      " 0.04441895 0.0664733  0.0151745  0.01514551 0.01422454 0.24118673]\n"
     ]
    }
   ],
   "source": [
    "target = 'occupation'\n",
    "clf, model, size, X, y = select_predictors(df, ft_language, target)\n",
    "ft_selected = model.get_feature_names_out(ft_language)\n",
    "ft_importance = clf.feature_importances_\n",
    "print('Input data size: ' + str(size))\n",
    "print(ft_selected)\n",
    "print(ft_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20e899e",
   "metadata": {},
   "source": [
    "#### Nationality - does not run because too many nationalities!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa75161",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'nationality'\n",
    "clf, model, size, X, y = select_predictors(df, ft_language, target)\n",
    "ft_selected = model.get_feature_names_out(ft_language)\n",
    "ft_importance = clf.feature_importances_\n",
    "print('Input data size: ' + str(size))\n",
    "print(ft_selected)\n",
    "print(ft_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a16231",
   "metadata": {},
   "source": [
    "### Agglomeration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d02af98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 24)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[ft_language].copy().to_numpy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6d77ea20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 22)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agglo = cluster.FeatureAgglomeration(n_clusters=None, distance_threshold=120)\n",
    "agglo.fit(X)\n",
    "X_reduced = agglo.transform(X)\n",
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bed646ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.194444</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.080655</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.191667</td>\n",
       "      <td>-0.636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028382</td>\n",
       "      <td>0.291</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1    2    3    4    5    6     7    8    9   ...   12    13  \\\n",
       "0  0.194444 -0.478  1.0  0.0 -1.0 -1.0 -1.0  12.0  0.0  0.0  ... -1.0   9.0   \n",
       "1  0.080655  0.301  0.0  1.0 -1.0  0.0 -1.0  35.0 -1.0  0.0  ... -1.0  32.0   \n",
       "2  0.191667 -0.636  0.0  0.0  0.0  0.0 -1.0  10.0  0.0  0.0  ... -1.0   8.0   \n",
       "3  0.028382  0.291 -0.6  0.0 -0.6  0.2 -1.0  24.0  0.0  0.0  ... -1.0  23.0   \n",
       "4  0.022222  0.000  0.0  0.0  0.0 -1.0  0.0  15.0  0.0  0.0  ...  0.0  14.0   \n",
       "\n",
       "    14   15   16   17        18   19   20   21  \n",
       "0  1.0  0.0  1.0  0.0  0.333333  0.0  0.0  0.0  \n",
       "1  1.0  0.0  1.0 -1.0  0.187500  0.0  0.0  0.0  \n",
       "2  1.0  0.0  1.0  0.0  0.000000  1.0  0.0  0.0  \n",
       "3  1.0  0.0  0.0  0.0  0.217391  1.0  0.0  0.0  \n",
       "4  0.0  0.0  1.0  0.0  0.142857  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.DataFrame(X_reduced)\n",
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53b265f",
   "metadata": {},
   "source": [
    "## Dictionary - not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bea89aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "gender = {\n",
    "    'Male': 0,\n",
    "    'Female': 1,\n",
    "    'Other': 2\n",
    "}\n",
    "\n",
    "religion = {\n",
    "    'Christian': 0,\n",
    "    'Hindus': 1, \n",
    "    'Muslim': 2, \n",
    "    'Jewish': 3,\n",
    "    'Other': 4 \n",
    "}\n",
    "\n",
    "academic_degree = {\n",
    "    'Bachelor': 0, \n",
    "    'Master': 1,\n",
    "    'Doctorate': 2, \n",
    "    'Other': 3\n",
    "}\n",
    "\n",
    "occupation = {\n",
    "    'Politics': 0, \n",
    "    'Arts': 1, \n",
    "    'Military': 2, \n",
    "    'Sciences': 3, \n",
    "    'Business': 4,\n",
    "    'Sports': 5, \n",
    "    'Religion': 6,\n",
    "    'Other': 7\n",
    "}\n",
    "\n",
    "nationality = defaultdict()\n",
    "nationalities = df_s.nationality.unique()\n",
    "for i in range(len(nationalities)):\n",
    "    nationality[nationalities[i]] = i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
